{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Shibu Mohapatra\n",
        "\n",
        "Artificial Intelligence"
      ],
      "metadata": {
        "id": "XYlXus3blUB2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDi2qbpjPiOt"
      },
      "source": [
        "**ANN execution in Numpy to show Forward Propagation Through Time (FPTT).**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import exp, array, random, dot\n",
        "training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "training_set_outputs = array([[0, 1, 1, 0]]).T\n",
        "random.seed(1)\n",
        "synaptic_weights = 2 * random.random((3, 1)) - 1\n",
        "for iteration in range(10000):\n",
        "    output = 1 / (1 + exp(-(dot(training_set_inputs, synaptic_weights))))\n",
        "    synaptic_weights += dot(training_set_inputs.T, (training_set_outputs - output) * output * (1 - output))\n",
        "print (1 / (1 + exp(-(dot(array([1, 0, 0]), synaptic_weights)))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH6Au7MuRUXT",
        "outputId": "98ccef9e-6197-45a1-be13-2664cb49f659"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99993704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T-ee4vGnMci"
      },
      "source": [
        "**Keras Neural Network on a Structured Data with prediction.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reference: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/ \n",
        "# first neural network with keras make predictions\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load the dataset\n",
        "dataset = loadtxt('/content/pima-indians-diabetes.csv', delimiter=',')\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# make class predictions with the model\n",
        "predictions = (model.predict(X) > 0.5).astype(int)\n",
        "\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a525f17-934b-4e36-ac3c-f0440b759df5",
        "id": "nK8sFpvmnMcn"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdUXaRCznnte"
      },
      "source": [
        "**Artificial Neural Network with MNIST Data.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "#Load the Dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# reshaping X data: (n, 28, 28) => (n, 784)\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "# converting y data into categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "#Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_shape = (784, )))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#Compile the model\n",
        "sgd = optimizers.SGD(lr = 0.01)\n",
        "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#Fit the model\n",
        "history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)\n",
        "\n",
        "#Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd9318c-33d7-419a-b08c-4ba491ab5a1e",
        "id": "3o-BU_VLnntn"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 1.4900 - accuracy: 0.5622\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 1.0575 - accuracy: 0.7041\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.8846 - accuracy: 0.7499\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.7794 - accuracy: 0.7671\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.7132 - accuracy: 0.7853\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.7908\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6379 - accuracy: 0.7988\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.6146 - accuracy: 0.8021\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5929 - accuracy: 0.8073\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5757 - accuracy: 0.8111\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5596 - accuracy: 0.8138\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5509 - accuracy: 0.8170\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5392 - accuracy: 0.8198\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5308 - accuracy: 0.8223\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5230 - accuracy: 0.8244\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5187 - accuracy: 0.8247\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5100 - accuracy: 0.8256\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.8284\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4974 - accuracy: 0.8313\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5047 - accuracy: 0.8270\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5034 - accuracy: 0.8277\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4902 - accuracy: 0.8316\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.8310\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4845 - accuracy: 0.8331\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4799 - accuracy: 0.8338\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4764 - accuracy: 0.8345\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4754 - accuracy: 0.8356\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4744 - accuracy: 0.8378\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4796 - accuracy: 0.8338\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4779 - accuracy: 0.8364\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4608 - accuracy: 0.8400\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4643 - accuracy: 0.8389\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4588 - accuracy: 0.8403\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4621 - accuracy: 0.8374\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4560 - accuracy: 0.8425\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4592 - accuracy: 0.8407\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4603 - accuracy: 0.8414\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4604 - accuracy: 0.8395\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4628 - accuracy: 0.8382\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.8431\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8418\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4487 - accuracy: 0.8434\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4496 - accuracy: 0.8433\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.8462\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4435 - accuracy: 0.8422\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.8457\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.8472\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4390 - accuracy: 0.8468\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4349 - accuracy: 0.8481\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8425\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4391 - accuracy: 0.8458\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4385 - accuracy: 0.8463\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4298 - accuracy: 0.8487\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4293 - accuracy: 0.8495\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 1s 5ms/step - loss: 0.4269 - accuracy: 0.8476\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4310 - accuracy: 0.8489\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.8475\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4268 - accuracy: 0.8511\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8525\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.8493\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.8500\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4194 - accuracy: 0.8524\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.8503\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4282 - accuracy: 0.8476\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4188 - accuracy: 0.8515\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8533\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4230 - accuracy: 0.8510\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4224 - accuracy: 0.8524\n",
            "Epoch 69/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4166 - accuracy: 0.8530\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4145 - accuracy: 0.8542\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.8526\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4233 - accuracy: 0.8503\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8524\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4116 - accuracy: 0.8542\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4108 - accuracy: 0.8546\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8563\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8531\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4135 - accuracy: 0.8542\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.8542\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4094 - accuracy: 0.8539\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4022 - accuracy: 0.8563\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8562\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4119 - accuracy: 0.8522\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4089 - accuracy: 0.8551\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8594\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8529\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4035 - accuracy: 0.8547\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.8557\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4018 - accuracy: 0.8558\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4001 - accuracy: 0.8565\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3976 - accuracy: 0.8599\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8585\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4047 - accuracy: 0.8565\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4000 - accuracy: 0.8573\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3931 - accuracy: 0.8597\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4003 - accuracy: 0.8555\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4014 - accuracy: 0.8564\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3950 - accuracy: 0.8579\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.8574\n",
            "Epoch 100/100\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3930 - accuracy: 0.8579\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8360\n",
            "Test accuracy:  0.8360000252723694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U524xQrn5Io"
      },
      "source": [
        "**Artificial Neural Network for Multiplication.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(150, activation='relu', input_shape=(2,)))\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "\n",
        "data = np.random.random((10000, 2))\n",
        "results = np.asarray([a * b for a, b in data])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='mae')\n",
        "\n",
        "model.fit(data, results, epochs=1, batch_size=1)\n",
        "\n",
        "model.predict([[0.8, 0.5]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ae592a-16f3-48e8-fce3-3e177971d77b",
        "id": "NXrOOg2Dn5JB"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0307\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43080878]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMn1OWzvoESU"
      },
      "source": [
        "**Artificial Neural Network for EVEN and ODD Numbers.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Create dataset\n",
        "X = np.zeros(1000, dtype=int)\n",
        "y = np.zeros(1000, dtype=int)\n",
        "\n",
        "#Even and odd numbers\n",
        "for number in range(1000):\n",
        "    X[number] = number\n",
        "    y[number] = (number+1) % 2\n",
        "\n",
        "binaries = [\"{0:b}\".format(x) for x in X] #convert integers in binary\n",
        "max_len = max([len(x) for x in binaries])\n",
        "same_len_bin = ['0'*(max_len-len(x))+x for x in binaries] #all inputs must have same len\n",
        "X = np.array([[int(n) for n in x] for x in same_len_bin]) #list of bits\n",
        "\n",
        "#Create the ANN model\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units = 3, activation = 'relu', input_dim = 10))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "classifier.fit(X, y, epochs = 100, batch_size  = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc87916-03ae-4bb1-8437-640cb6aa5177",
        "id": "GLzqdZ2NoESZ"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.8038 - accuracy: 0.4390\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.4450\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.4490\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7333 - accuracy: 0.4570\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.4660\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.4800\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.4870\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.4870\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.4920\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.4990\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.5030\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5050\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.5090\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5190\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5270\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5290\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5350\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5370\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6887 - accuracy: 0.5410\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5460\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5430\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5520\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5580\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5610\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5640\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5710\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5760\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5850\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5900\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.5930\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.6060\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6140\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6270\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6400\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6500\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6640\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6780\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6930\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6990\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7120\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.7320\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7480\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7700\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7770\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7950\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.8210\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.8750\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.9160\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.9580\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.9800\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.9940\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.9970\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3017b34250>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}